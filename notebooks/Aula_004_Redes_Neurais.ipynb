{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 004: Redes Neurais.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyhKkwSsnPpl2BJ9bLGKyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfab/escola-data-science/blob/master/notebooks/Aula_004_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHE3cU40ARW",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/eds.png\" height=\"100px\"></p>\n",
        "\n",
        "# Aula 004: Redes Neurais\n",
        "\n",
        "Redes neurais (NN) são os blocos construtores fundamentais do Deep Learning. Sua popularidade se dá devido a capacidade de lidar com problemas altamente complexos, onde algoritmos tradicionais não foram capazes de obter sucesso.\n",
        "\n",
        "Entre as principais aplicações das NN estão os carros autônomos, reconhecimento de objetos em imagens, tradução entre idiomas, legendas automáticas em vídeos, entre outras.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/human-neuron.png\" height=\"400px\"></p>\n",
        "\n",
        "Como foi mencionado na apresentação de slides, as NN são inspiradas neurônios biológicos da vida real, aqueles que temos no nosso próprio sistema nervoso - aproximadamente 10 bilhões.\n",
        "\n",
        "Cada um dos nossos neurônios está conectado a cerca de 10 mil outros neurônios. A comunicação entre esses neurônios ocorre por meio de impulsos captados pelos dendritos. Na sequência, esses impulsos são transmitidos pelo corpo do neurônio, por meio do axônio, até atingirem os dendritos de neurônios vizinhos através de sinapses.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/simple-nn.png\" height=\"300px\"></p>\n",
        "\n",
        "Se ficou difícil de imaginar esse paralelo entre o mundo real e artificial, veja a imagem abaixa comparando redes neurais biológicas e artificiais, bio-inspirados:\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/comparativo_nn.png\" height=\"250px\"></p>\n",
        "\n",
        "Abandonando um pouco \n",
        "\n",
        "Em um NN artificial, recebem-se valores $x_1, x_2, x_3$, jutamente com uma constante conhecida como *bias*, que são multiplicados por pesos $w_1, w_2, w_3, w_4$ e somados. Por fim, essa soma passa por uma função de ativação, que irá fornecer o *output*.\n",
        "\n",
        "Matematicamente, a saída (*output*) da NN pode ser escrita de várias formas diferentes. Tipicamente você irá encontrar  a forma matemática, escrita como uma única equação:\n",
        "\n",
        "$$\n",
        "\\hat{y} = g \\left(w_0 + \\sum_{i=1}^{m} x_iw_i \\right) \\\\\n",
        "$$\n",
        "\n",
        "ou podemos escrever a mesma coisa usando a Algebra Linear em termos de vetores e produtos escalares:\n",
        "\n",
        "$$\n",
        "\\hat{y} = g \\left( w_0 + X^T W \\right) \\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "X&=\n",
        "    \\begin{bmatrix}\n",
        "        x_1 \\\\ \\vdots \\\\ x_2\n",
        "    \\end{bmatrix} \n",
        "&&W=\n",
        "    \\begin{bmatrix}\n",
        "        w_1 \\\\ \\vdots \\\\ w_m\n",
        "    \\end{bmatrix} \\\\\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZAhbxor1mV",
        "colab_type": "text"
      },
      "source": [
        "### Um exemplo de Rede Neural simples\n",
        "\n",
        "Veja a imagem abaixo, onde temos uma NN que recebe dois *inputs* e fornece um resultado de saída.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/exemplo-nn.png\" height=\"250px\"></p>\n",
        "\n",
        "Nessa situação acima temos:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "X&=\n",
        "    \\begin{bmatrix}\n",
        "        x_1 \\\\ x_2\n",
        "    \\end{bmatrix} \n",
        "&&W=\n",
        "    \\begin{bmatrix}\n",
        "        -2 \\\\ \\\\ 5\n",
        "    \\end{bmatrix}\n",
        "&&w_0=1\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Matematicamente, o resultado final $\\hat{y}$ poderia ser escrito como $\\hat{y} = g(1 - 2x_1 +5x_2)$. No entanto, isso resolve apenas uma parte do problema.\n",
        "\n",
        "O poder do *Deep Learning* está em usar a não-lineariedade para resolver problemas complexos. É aí que entra a **função de ativação**, tema muito amplo (e que terá uma aula exclusiva para ele).\n",
        "\n",
        "Vamos apenas assumir que será usada a **função sigmoidal** (e sua curva ***sigmoidal***) para fornecer à nossa NN essa tal não-lineariedade.\n",
        "\n",
        "$$\n",
        "g(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Não entendeu essa questão da lineariedade? \n",
        "\n",
        "Visualmente, veja na figura abaixo (extraída do MIT) como a parte linear $w_0 + \\sum_{i=1}^{m} x_iw_i$ da nossa equação não conseguiria separar corretamente as classes, não importando quantas camadas de neurônios existissem.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/linear-vs-nao-linear.png\" height=\"250px\"></p>\n",
        "\n",
        "Já quando você utiliza essa parte linear dentro de uma função de ativação $\\sigma(w_0 + \\sum_{i=1}^{m} x_iw_i)$, possibilita que esse tipo de curva não-linear possa ocorrer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph4QuYgt1C9c",
        "colab_type": "code",
        "outputId": "15443416-76a9-4dff-8b42-f7a6ab9c63af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# importar as bibliotecas necessárias\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# configurações do notebook\n",
        "sns.set_style()\n",
        "\n",
        "# importar dataset simplificado (variáveis numéricas)\n",
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOyF91p524wq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11667094-d8cc-4691-95b7-49d21fa4f52a"
      },
      "source": [
        "# exemplo dado na aula de rede neural:\n",
        "def sigmoid(x): \n",
        "    return 1.0/(1 + np.exp(-x))\n",
        "\n",
        "# valores de input\n",
        "x1 = 10\n",
        "x2 = -2\n",
        "\n",
        "# soma de w0 + X.W\n",
        "res = 1 -2*x1 + 5*x2\n",
        "\n",
        "# função de ativação sigmoid\n",
        "yhat = sigmoid(res)\n",
        "print(yhat)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.543665647376276e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCxQBzJu6lpX",
        "colab_type": "text"
      },
      "source": [
        "## Redes Neurais ao *dataset* imobiliário da California"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh4GhirYK5g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar o dataset e lista com nomes das features\n",
        "dataset = fetch_california_housing()\n",
        "features = dataset.feature_names\n",
        "\n",
        "# dividir entre treino, validação e teste\n",
        "X_train_original, X_test, y_train_original, y_test = train_test_split(dataset.data, dataset.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_original, y_train_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECcHLMsGGRWV",
        "colab_type": "code",
        "outputId": "0126dfd9-7543-49e8-853a-39619ae36bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ver como ficaria em formato de DataFrame\n",
        "df = pd.DataFrame(X_train)\n",
        "df.columns = features\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.9028</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.470968</td>\n",
              "      <td>0.987097</td>\n",
              "      <td>436.0</td>\n",
              "      <td>2.812903</td>\n",
              "      <td>39.52</td>\n",
              "      <td>-121.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.2160</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8.443836</td>\n",
              "      <td>1.246575</td>\n",
              "      <td>771.0</td>\n",
              "      <td>2.112329</td>\n",
              "      <td>33.61</td>\n",
              "      <td>-117.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.9063</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.463235</td>\n",
              "      <td>1.139706</td>\n",
              "      <td>226.0</td>\n",
              "      <td>1.661765</td>\n",
              "      <td>36.98</td>\n",
              "      <td>-122.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0385</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.565574</td>\n",
              "      <td>0.981557</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>2.299180</td>\n",
              "      <td>33.67</td>\n",
              "      <td>-117.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.2250</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.935484</td>\n",
              "      <td>1.163594</td>\n",
              "      <td>1099.0</td>\n",
              "      <td>2.532258</td>\n",
              "      <td>33.66</td>\n",
              "      <td>-117.91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    MedInc  HouseAge  AveRooms  ...  AveOccup  Latitude  Longitude\n",
              "0   3.9028      25.0  5.470968  ...  2.812903     39.52    -121.49\n",
              "1  11.2160      36.0  8.443836  ...  2.112329     33.61    -117.91\n",
              "2   1.9063      21.0  4.463235  ...  1.661765     36.98    -122.02\n",
              "3   4.0385      12.0  4.565574  ...  2.299180     33.67    -117.99\n",
              "4   3.2250      21.0  3.935484  ...  2.532258     33.66    -117.91\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEbqJIGGGg7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padronizar os dados com StandardScaler por causa do Gradient Descent\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_valid = scaler.transform(X_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKKeXLa1OIv0",
        "colab_type": "code",
        "outputId": "a8823962-bfd6-40f0-d782-9a1db5e11469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ver o dataset padronizado\n",
        "pd.DataFrame(X_train).head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011008</td>\n",
              "      <td>-0.291465</td>\n",
              "      <td>0.016340</td>\n",
              "      <td>-0.254890</td>\n",
              "      <td>-0.868446</td>\n",
              "      <td>-0.032641</td>\n",
              "      <td>1.822806</td>\n",
              "      <td>-0.955460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.861743</td>\n",
              "      <td>0.585238</td>\n",
              "      <td>1.262597</td>\n",
              "      <td>0.354491</td>\n",
              "      <td>-0.574811</td>\n",
              "      <td>-0.149520</td>\n",
              "      <td>-0.948550</td>\n",
              "      <td>0.829391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.040240</td>\n",
              "      <td>-0.610267</td>\n",
              "      <td>-0.406112</td>\n",
              "      <td>0.103510</td>\n",
              "      <td>-1.052515</td>\n",
              "      <td>-0.224689</td>\n",
              "      <td>0.631733</td>\n",
              "      <td>-1.219698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.082461</td>\n",
              "      <td>-1.327569</td>\n",
              "      <td>-0.363211</td>\n",
              "      <td>-0.267899</td>\n",
              "      <td>-0.267152</td>\n",
              "      <td>-0.118347</td>\n",
              "      <td>-0.920414</td>\n",
              "      <td>0.789506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.345884</td>\n",
              "      <td>-0.610267</td>\n",
              "      <td>-0.627351</td>\n",
              "      <td>0.159612</td>\n",
              "      <td>-0.287312</td>\n",
              "      <td>-0.079462</td>\n",
              "      <td>-0.925104</td>\n",
              "      <td>0.829391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0  0.011008 -0.291465  0.016340  ... -0.032641  1.822806 -0.955460\n",
              "1  3.861743  0.585238  1.262597  ... -0.149520 -0.948550  0.829391\n",
              "2 -1.040240 -0.610267 -0.406112  ... -0.224689  0.631733 -1.219698\n",
              "3  0.082461 -1.327569 -0.363211  ... -0.118347 -0.920414  0.789506\n",
              "4 -0.345884 -0.610267 -0.627351  ... -0.079462 -0.925104  0.829391\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNAfFA2Gw3n",
        "colab_type": "code",
        "outputId": "893398e8-df6d-42f9-f572-8467a2b250fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# construir uma nn\n",
        "model = keras.models.Sequential(\n",
        "    [\n",
        "     keras.layers.Dense(30, activation='relu', input_shape=(X_train.shape[1:])),\n",
        "     keras.layers.Dense(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# compilar a nn \n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "# obter o histórico de loss\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# verificar o MSE\n",
        "error = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/50\n",
            "11610/11610 [==============================] - 1s 71us/sample - loss: 0.7691 - val_loss: 0.4773\n",
            "Epoch 2/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5383 - val_loss: 0.4286\n",
            "Epoch 3/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4690 - val_loss: 0.4083\n",
            "Epoch 4/50\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4216 - val_loss: 0.3945\n",
            "Epoch 5/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4094 - val_loss: 0.3842\n",
            "Epoch 6/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4006 - val_loss: 0.3761\n",
            "Epoch 7/50\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3936 - val_loss: 0.3701\n",
            "Epoch 8/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3915 - val_loss: 0.3789\n",
            "Epoch 9/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3872 - val_loss: 0.3631\n",
            "Epoch 10/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3803 - val_loss: 0.3625\n",
            "Epoch 11/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3778 - val_loss: 0.3607\n",
            "Epoch 12/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3746 - val_loss: 0.3579\n",
            "Epoch 13/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3833 - val_loss: 0.3649\n",
            "Epoch 14/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3708 - val_loss: 0.3526\n",
            "Epoch 15/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3832 - val_loss: 0.3625\n",
            "Epoch 16/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3727 - val_loss: 0.3575\n",
            "Epoch 17/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3668 - val_loss: 0.3505\n",
            "Epoch 18/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3633 - val_loss: 0.3498\n",
            "Epoch 19/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3601 - val_loss: 0.3563\n",
            "Epoch 20/50\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3590 - val_loss: 0.3490\n",
            "Epoch 21/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3598 - val_loss: 0.3463\n",
            "Epoch 22/50\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3560 - val_loss: 0.3411\n",
            "Epoch 23/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3531 - val_loss: 0.3615\n",
            "Epoch 24/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3551 - val_loss: 0.3381\n",
            "Epoch 25/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3535 - val_loss: 0.3388\n",
            "Epoch 26/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3495 - val_loss: 0.3364\n",
            "Epoch 27/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3487 - val_loss: 0.3640\n",
            "Epoch 28/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3516 - val_loss: 0.3388\n",
            "Epoch 29/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3480 - val_loss: 0.3355\n",
            "Epoch 30/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3449 - val_loss: 0.3513\n",
            "Epoch 31/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3460 - val_loss: 0.3372\n",
            "Epoch 32/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3463 - val_loss: 0.3304\n",
            "Epoch 33/50\n",
            "10400/11610 [=========================>....] - ETA: 0s - loss: 0.3444"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuyh8wIHyMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fazer uma nova previsão \n",
        "new_house = X_train[0].reshape(1,-1)\n",
        "model.predict(new_house)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgKybZ0t7bQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotar historico \n",
        "pd.DataFrame(history.history).plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOtzc4i8Pml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}